import logging
from typing import Dict, Any

import tqdm
from pandas import DataFrame
from sqlalchemy.engine import Engine

from prompts.comment_creator import CommentCreator
from prompts.info_extractor import InfoExtractor
from utils.config_loaders import (
    get_config
)
from utils.database import get_table_info, get_data

config = get_config()


def generate_sql_code(
        gpt_comments: dict,
        schema_name: str,
        table_name: str
) -> str:
    """
    Generate SQL code from GPT-3 comments
    Args:
        gpt_comments: Comments generated by GPT-3
        schema_name: Schema name
        table_name: Table name

    Returns: SQL code to be executed in the database to add comments

    """
    logging.info(f'Generating SQL code for table {table_name} and schema {schema_name}')
    sql_code = ''
    for column in gpt_comments['columns']:
        sql_code += f"COMMENT ON COLUMN {schema_name}.{table_name}.{column['column_name']} IS '{column['comment']}';\n"
    return sql_code


def process_columns_in_chunks(
        table_name: str,
        schema_name: str,
        columns_info: list,
        pandas_info: DataFrame,
        chunk_size: int = 5
) -> Dict[str, Any]:
    """
    Process the columns in chunks to avoid memory issues and tokens limit
    Args:
        table_name: Table name to be processed
        schema_name: Schema name to be processed
        columns_info: Dictionary with the columns information (metadata)
        pandas_info: Pandas dataframe with the data related to the table
        chunk_size: Size of the chunk to be processed

    Returns: Dictionary with the table name, schema name and columns information

    """
    final_result = {
        'table_name': table_name,
        'schema_name': schema_name,
        'columns': []
    }
    logging.info(f'Processing table {table_name} and schema {schema_name}')
    for i in tqdm.tqdm(range(0, len(columns_info), chunk_size)):
        logging.info(f'Processing chunk {i}, table {table_name} and schema {schema_name}')
        # Get a 'chunk' of the list of size 'chunk_size'
        columns_info_chunk = columns_info[i:i + chunk_size]
        column_name = [column['column_name'] for column in columns_info_chunk]
        pandas_info_chunk = pandas_info[pandas_info.columns.intersection(column_name)]
        comments = CommentCreator(
            table_name=table_name,
            schema_name=schema_name,
            table_info=columns_info_chunk,
            table_data=pandas_info_chunk
        )
        result = comments.get_result()
        final_result['columns'] += result['columns']
    return final_result


def get_info(query: str, database: Engine):
    try:
        info_extractor = InfoExtractor(query=query).get_result()
        table_data = get_data(info_extractor, database, 50)
        table_metadata = get_table_info(info_extractor, database)

        return info_extractor, table_data, table_metadata
    except Exception as e:
        logging.error(f"Failed to get the metadata or the dataframe: {str(e)}")
        return 'No comments were generated, failed to get the metadata or the dataframe'


def run_sql_comment_generator(query: str, database: Engine) -> str:
    """
    Run the SQL comment generator
    Args:
        query: User question to be processed
        database: Database connection object

    Returns: SQL code to be executed in the database to add comments

    """
    logging.info(f'Running SQL comment generator')
    info_extractor, table_data, table_metadata = get_info(query, database)

    try:
        sql_code = ''
        for schema_name, table_names in info_extractor['schemas'].items():
            for table_name in table_names:
                # Getting table data
                columns_info = table_metadata[f'{schema_name}.{table_name}']['columns']
                pandas_info = table_data[f'{schema_name}.{table_name}']
                # Processing columns
                result = process_columns_in_chunks(
                    table_name,
                    schema_name,
                    columns_info,
                    pandas_info,
                    chunk_size=20
                )
                # Generating SQL code
                sql_code += generate_sql_code(result, schema_name, table_name)
        return sql_code
    except Exception as e:
        logging.error(f"Failed to generate the SQL comments: {str(e)}")
        return f"No comments were generated, failed to generate the SQL code, Don't try again: {str(e)}"
